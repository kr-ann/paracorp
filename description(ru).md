# Описание решения.
  <b>1.	Предобработка текста.</b> Удаляем знаки препинания и лемматизируем текст. Этот этап необходим: на одном из следующих шагов будем переводить слова с помощью словаря, там нужны леммы. 
  
Хотя Мультитран, например, понимает, когда в качестве входного значения передаётся нелемматизированое слово, но если, например, словарь выдаст, что «friends» = «друг», а в русском предложении будет форма «друзьям», то у нас просто не получится связать два этих слова. 

  <b>2.	Построение обучающего корпуса.</b> Корпус с новостями содержит положительные примеры (действительно параллельные предложения). Чтобы получить отрицательные примеры, мы комбинируем друг с другом предложения из этого корпуса, которые не находятся в паре друг с другом. Их очень много, но оставляем только удовлетворяющие условиям:
  
    a.	соотношение длин предложений не больше двух (=не меньше 0,5);
    b.	как минимум 40% слов в предложении имеют переводной эквивалент в другом предложении (в две стороны: английский-русский и русский-английский).
    
Делаем это, чтобы отрицательные примеры не были слишком простыми и классификатор не присваивал слишком большой вес соответствующим признакам. Но следует отметить, что даже в золотом стандарте не все предложения, как оказалось, удовлетворяют этим правилам (445 пар по этим критериям не подходят), но их мы, конечно, оттуда не убираем.

Даже после применения таких ограничений отрицательных примеров оставалось гораздо больше, чем положительных (1,473,229 по отношению к ~9000), поэтому дальше выбираем рандомные ~10000 штук из отрицательных примеров, чтобы корпус был сбалансированным.

  <b>3.	Классификатор Maximum Entropy</b> (= LogisticRegression в sklearn.linear_model). Объект – пара предложений (их номер). Признаки – 
  
    a.	длина предложения 1 (в знаках)
    b.	длина предложения 2
    c.	разность длин
    d.	соотношение длин
    e.	отклонения соотношения от среднего (по корпусу с новостями – золотому стандарту)
    f.	количество английских слов, которые не имеют переводов в русском предложении
    g.	их процент по отношению к длине английского предложения 
    h.	количество русских слов, которые не имеют переводов в английском предложении
    i.	их процент по отношению к длине русского предложения 
    
Как находится значение признака f (и, аналогично, h)? Сначала для каждого слова в английском предложении мы находим все его переводы на русский (из Мультитрана, потому что к нему удобно подключаться и он выдаёт достаточно большой список значений). Если переводом английского слова является словосочетание, мы смотрим, чтобы в предложении эти два слова шли друг за другом (предварительно лемматизируя).

Качество классификатора – при кросс-валидации среднее значение f-меры = 0,87.

  <b>4.	Вычисление признаков для корпуса Википедии.</b> Можно было бы для предложений из этого корпуса, как и для новостного, сначала проверять условия про соотношение длин и процент переводных эквивалентов, а предложения, которые им не удовлетворяют, сразу считать непараллельными. Но так как даже для части предложений из золотого стандарта условия не соблюдаются, я приняла решение сразу вычислять значение признаков для каждой пары, за исключением нескольких вариантов:
  
    a.	если длина обоих предложений равна нулю, мы сразу считаем их параллельными, потому что нулевая длина, скорее всего, свидетельствует о том, что такие предложения до лемматизации состояли только из неалфавитных символов (например, цифр);
    b.	если длина одного предложения равна нулю, а второго – нет, то такие предложения, по тем же соображениям, сразу считаются непараллельными.
    
Затем применяем классификатор и записываем результат в файл.

В этой работе я опиралась на некоторые идеи из статьи [Munteanu and Marcu 2005 – Improving Machine Translation Performance by Exploiting Non-Parallel Corpora].
